{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN/npX6T7tdvAPxyFPtAb0P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlphaZero3d/NewsScrapeAndSentimentAnalyzer/blob/main/News_Sentiment_Analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#News Sentiment Analyzer"
      ],
      "metadata": {
        "id": "0jIM0fUDF-pZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copyright (c) 2023, Alphaero3d@gmail.com\n",
        "All rights reserved.\n",
        "\n",
        "This source code is licensed under the BSD-style license found in the\n",
        "LICENSE file in the root directory of this source tree."
      ],
      "metadata": {
        "id": "EKRaLFYsK2LH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Install requirements"
      ],
      "metadata": {
        "id": "o4gmGoM2EkXM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgWFsvQmEKsA"
      },
      "outputs": [],
      "source": [
        "!pip install requests beautifulsoup4 nltk lxml\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Run Program"
      ],
      "metadata": {
        "id": "v3xEwa6wErfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "#nltk.download('vader_lexicon')\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "\n",
        "def scrape_news(url):\n",
        "  \"\"\"Scrapes the top headlines from a news website.\"\"\"\n",
        "  response = requests.get(url)\n",
        "  soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "  news_list = soup.find_all(\"item\")\n",
        "  return news_list\n",
        "\n",
        "def analyze_sentiment(news_list):\n",
        "  \"\"\"Analyzes the sentiment of the top headlines from a news website.\"\"\"\n",
        "  analyzer = SentimentIntensityAnalyzer()\n",
        "  sentiments = []\n",
        "  for news in news_list:\n",
        "    title_sentiment = analyzer.polarity_scores(news.title.text)\n",
        "\n",
        "    description_sentiment = analyzer.polarity_scores(news.description.text)\n",
        "    sentiments.append((title_sentiment, description_sentiment))\n",
        "  return sentiments\n",
        "\n",
        "def sum_sentiment_scores(sentiments):\n",
        "  \"\"\"Sums the values in the 'neg', 'neu', and 'pos' columns of the sentiment scores.\"\"\"\n",
        "  neg_sum = 0\n",
        "  neu_sum = 0\n",
        "  pos_sum = 0\n",
        "  for title_sentiment, description_sentiment in sentiments:\n",
        "    neg_sum += title_sentiment['neg'] + description_sentiment['neg']\n",
        "    neu_sum += title_sentiment['neu'] + description_sentiment['neu']\n",
        "    pos_sum += title_sentiment['pos'] + description_sentiment['pos']\n",
        "  return neg_sum, neu_sum, pos_sum\n",
        "\n",
        "#userterm = input()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  url  = \"https://news.google.com/news/rss\"\n",
        "  #url = \"https://news.google.com/rss/search?q=stocks&hl=en-US&gl=US&ceid=US%3Aen\"\n",
        "  #url = \"https://news.google.com/rss/search?q=bonds&hl=en-US&gl=US&ceid=US%3Aen\"\n",
        "  #url = \"https://news.google.com/rss/search?q=earnings&hl=en-US&gl=US&ceid=US%3Aen\"\n",
        "  #url = \"https://news.google.com/rss/search?q=netflix&hl=en-US&gl=US&ceid=US%3Aen\"\n",
        "  #url = \"https://www.npr.org/sections/news/\"\n",
        "  #url = \"http://feeds.bbci.co.uk/news/rss.xml\"\n",
        "  #url = \"https://www.ft.com/news-feed/rss.xml\"\n",
        "  #url = \"https://www.nasdaq.com/feed/rssoutbound?category=Stocks/rss.xml\"\n",
        "  #url = \"https://news.google.com/rss/search?q=when:24h+allinurl:bloomberg.com&hl=en-US&gl=US&ceid=US:en\"\n",
        "  #url = \"https://news.google.com/rss/search?gl=US&hl=en-US&q=Tesla,+Inc.&ceid=US:en\"\n",
        "  #url = \"https://news.google.com/rss/search?q=when:24h+allinurl:bloomberg.com\"\n",
        "  #url = \"https://rss.nytimes.com/services/xml/rss/nyt/MostViewed.xml\"\n",
        "  news_list = scrape_news(url)\n",
        "  sentiments = analyze_sentiment(news_list)\n",
        "  neg_sum, neu_sum, pos_sum = sum_sentiment_scores(sentiments)\n",
        "  print(\"Negative sentiment:\", neg_sum)\n",
        "  print(\"Neutral sentiment:\", neu_sum)\n",
        "  print(\"Positive sentiment:\", pos_sum)\n",
        "  print(\"Positive - Negative Difference: \",pos_sum-neg_sum)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUSJMMRTELdL",
        "outputId": "008b9ad9-cbbf-4d12-ccc9-5b957ace6473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative sentiment: 7.061999999999999\n",
            "Neutral sentiment: 63.803\n",
            "Positive sentiment: 5.131\n",
            "Positive - Negative Difference:  -1.9309999999999992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Notes:\n",
        "Using google News we can change the \"search\" by editing the term that follows this line of code\n",
        "```\n",
        "search?q=\n",
        "```\n",
        "our new query will be:\n",
        "```\n",
        "search?q= NEW_TERM_HERE\n",
        "```\n",
        "the final string will look like this:\n",
        "```\n",
        "\"https://news.google.com/rss/search?q=NEW_TERM_HERE&hl=en-US&gl=US&ceid=US%3Aen\"\n",
        "```\n",
        "\n",
        "We could also create an updated code that takes user input to automate the html editing process, for instyance if we want to seach AAPL or dogs we can either edit the  \n",
        "\n",
        "```\n",
        "url = \"https://news.google.com/news/rss/search?q=AAPL\"\n",
        "```\n",
        "\n",
        "Alternativley we could take user input like this:\n",
        "\n",
        "```\n",
        "if __name__ == \"__main__\":\n",
        "  userterm = input()\n",
        "  url = \"https://news.google.com/news/rss/search?q={userterm}s&hl=en-US&gl=US&ceid=US%3Aen\"\n",
        "  news_list = scrape_news(url)\n",
        "  sentiments = analyze_sentiment(news_list)\n",
        "  neg_sum, neu_sum, pos_sum = sum_sentiment_scores(sentiments)\n",
        "  print(\"Negative sentiment:\", neg_sum)\n",
        "  print(\"Neutral sentiment:\", neu_sum)\n",
        "  print(\"Positive sentiment:\", pos_sum)\n",
        "  print(\"Positive - Negative Difference: \",pos_sum-neg_sum)\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "14guh89uGVUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The New Code With User input:"
      ],
      "metadata": {
        "id": "qHWC8EjXI0b0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "\n",
        "def scrape_news(url):\n",
        "  \"\"\"Scrapes the top headlines from a news website.\"\"\"\n",
        "  response = requests.get(url)\n",
        "  soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "  news_list = soup.find_all(\"item\")\n",
        "  return news_list\n",
        "\n",
        "def analyze_sentiment(news_list):\n",
        "  \"\"\"Analyzes the sentiment of the top headlines from a news website.\"\"\"\n",
        "  analyzer = SentimentIntensityAnalyzer()\n",
        "  sentiments = []\n",
        "  for news in news_list:\n",
        "    title_sentiment = analyzer.polarity_scores(news.title.text)\n",
        "\n",
        "    description_sentiment = analyzer.polarity_scores(news.description.text)\n",
        "    sentiments.append((title_sentiment, description_sentiment))\n",
        "  return sentiments\n",
        "\n",
        "def sum_sentiment_scores(sentiments):\n",
        "  \"\"\"Sums the values in the 'neg', 'neu', and 'pos' columns of the sentiment scores.\"\"\"\n",
        "  neg_sum = 0\n",
        "  neu_sum = 0\n",
        "  pos_sum = 0\n",
        "  for title_sentiment, description_sentiment in sentiments:\n",
        "    neg_sum += title_sentiment['neg'] + description_sentiment['neg']\n",
        "    neu_sum += title_sentiment['neu'] + description_sentiment['neu']\n",
        "    pos_sum += title_sentiment['pos'] + description_sentiment['pos']\n",
        "  return neg_sum, neu_sum, pos_sum\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  userterm = input()\n",
        "  url = \"https://news.google.com/news/rss/search?q={userterm}s&hl=en-US&gl=US&ceid=US%3Aen\"\n",
        "  news_list = scrape_news(url)\n",
        "  sentiments = analyze_sentiment(news_list)\n",
        "  neg_sum, neu_sum, pos_sum = sum_sentiment_scores(sentiments)\n",
        "  print(\"Negative sentiment:\", neg_sum)\n",
        "  print(\"Neutral sentiment:\", neu_sum)\n",
        "  print(\"Positive sentiment:\", pos_sum)\n",
        "  print(\"Positive - Negative Difference: \",pos_sum-neg_sum)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeGRFvNuI5v9",
        "outputId": "100fde59-e1b6-401b-87c0-6ad7d9b07c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "war\n",
            "Negative sentiment: 1.8489999999999998\n",
            "Neutral sentiment: 17.71\n",
            "Positive sentiment: 0.44199999999999995\n",
            "Positive - Negative Difference:  -1.4069999999999998\n"
          ]
        }
      ]
    }
  ]
}